{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Fashion-MNIST dataset...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Isaac\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Isaac\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DCGAN...\n",
      "Epoch 1, Gen Loss: 0.8797, Disc Loss: 1.0650, Time: 74.05 sec\n",
      "Epoch 2, Gen Loss: 0.9442, Disc Loss: 1.1992, Time: 128.00 sec\n",
      "Epoch 3, Gen Loss: 0.9004, Disc Loss: 1.2592, Time: 150.26 sec\n",
      "Epoch 4, Gen Loss: 0.8581, Disc Loss: 1.2715, Time: 98.43 sec\n",
      "Epoch 5, Gen Loss: 0.8106, Disc Loss: 1.3245, Time: 75.63 sec\n",
      "Epoch 6, Gen Loss: 0.8626, Disc Loss: 1.2714, Time: 75.60 sec\n",
      "Epoch 7, Gen Loss: 0.8691, Disc Loss: 1.2816, Time: 76.12 sec\n",
      "Epoch 8, Gen Loss: 0.8803, Disc Loss: 1.2718, Time: 78.94 sec\n",
      "Epoch 9, Gen Loss: 0.8775, Disc Loss: 1.2470, Time: 80.26 sec\n",
      "Epoch 10, Gen Loss: 0.8819, Disc Loss: 1.2039, Time: 77.20 sec\n",
      "Epoch 11, Gen Loss: 1.0022, Disc Loss: 1.1838, Time: 75.13 sec\n",
      "Epoch 12, Gen Loss: 0.9578, Disc Loss: 1.1583, Time: 75.08 sec\n",
      "Epoch 13, Gen Loss: 1.0315, Disc Loss: 1.1394, Time: 76.00 sec\n",
      "Epoch 14, Gen Loss: 1.0864, Disc Loss: 1.0272, Time: 76.36 sec\n",
      "Epoch 15, Gen Loss: 1.1537, Disc Loss: 1.0690, Time: 151.90 sec\n",
      "\n",
      "Training Diffusion Model...\n",
      "Epoch 1, Loss: 0.0462, Time: 106.55 sec\n",
      "Epoch 2, Loss: 0.0090, Time: 119.52 sec\n",
      "Epoch 3, Loss: 0.0067, Time: 95.96 sec\n",
      "Epoch 4, Loss: 0.0058, Time: 56.31 sec\n",
      "Epoch 5, Loss: 0.0052, Time: 60.31 sec\n",
      "Epoch 6, Loss: 0.0049, Time: 65.29 sec\n",
      "Epoch 7, Loss: 0.0046, Time: 69.10 sec\n",
      "Epoch 8, Loss: 0.0044, Time: 74.72 sec\n",
      "Epoch 9, Loss: 0.0043, Time: 77.54 sec\n",
      "Epoch 10, Loss: 0.0041, Time: 94.78 sec\n",
      "Epoch 11, Loss: 0.0040, Time: 116.15 sec\n",
      "Epoch 12, Loss: 0.0039, Time: 106.60 sec\n",
      "Epoch 13, Loss: 0.0038, Time: 99.31 sec\n",
      "Epoch 14, Loss: 0.0037, Time: 106.59 sec\n",
      "Epoch 15, Loss: 0.0036, Time: 123.33 sec\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dense' object has no attribute 'input_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 201\u001b[0m\n\u001b[0;32m    197\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m end_time \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m--> 201\u001b[0m dcgan_time \u001b[38;5;241m=\u001b[39m measure_generation_time(generator)\n\u001b[0;32m    202\u001b[0m diffusion_time \u001b[38;5;241m=\u001b[39m measure_generation_time(diffusion_model)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDCGAN generation time for 100 images: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdcgan_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 190\u001b[0m, in \u001b[0;36mmeasure_generation_time\u001b[1;34m(model, num_images)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeasure_generation_time\u001b[39m(model, num_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, keras\u001b[38;5;241m.\u001b[39mSequential) \u001b[38;5;129;01mand\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minput_shape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m100\u001b[39m):  \u001b[38;5;66;03m# DCGAN generator\u001b[39;00m\n\u001b[0;32m    191\u001b[0m         noise \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal([num_images, \u001b[38;5;241m100\u001b[39m])\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Diffusion model\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Dense' object has no attribute 'input_shape'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a directory for saving generated images\n",
    "if not os.path.exists('generated_images'):\n",
    "    os.makedirs('generated_images')\n",
    "\n",
    "# Load and preprocess the Fashion-MNIST dataset\n",
    "print(\"Loading Fashion-MNIST dataset...\")\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, _), (_, _) = fashion_mnist.load_data()\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # Normalize images to [-1, 1]\n",
    "\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Create tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "# DCGAN Generator\n",
    "def make_generator_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(7*7*256, use_bias=False, input_shape=(100,)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        \n",
    "        layers.Reshape((7, 7, 256)),\n",
    "        layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        \n",
    "        layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        \n",
    "        layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# DCGAN Discriminator\n",
    "def make_discriminator_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Simple Diffusion Model\n",
    "def make_diffusion_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=[28, 28, 1]),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "        layers.Conv2D(1, (3, 3), activation='tanh', padding='same')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Loss functions\n",
    "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "# Optimizers\n",
    "generator_optimizer = keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = keras.optimizers.Adam(1e-4)\n",
    "diffusion_optimizer = keras.optimizers.Adam(1e-3)\n",
    "\n",
    "# Create models\n",
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()\n",
    "diffusion_model = make_diffusion_model()\n",
    "\n",
    "# Training steps\n",
    "@tf.function\n",
    "def train_step_gan(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, 100])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "@tf.function\n",
    "def train_step_diffusion(images):\n",
    "    noise = tf.random.normal(shape=images.shape)\n",
    "    noisy_images = images + 0.1 * noise\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        reconstructed = diffusion_model(noisy_images, training=True)\n",
    "        loss = tf.reduce_mean(tf.square(images - reconstructed))\n",
    "\n",
    "    gradients = tape.gradient(loss, diffusion_model.trainable_variables)\n",
    "    diffusion_optimizer.apply_gradients(zip(gradients, diffusion_model.trainable_variables))\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Training loops\n",
    "def train_gan(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        gen_loss_list = []\n",
    "        disc_loss_list = []\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step_gan(image_batch)\n",
    "            gen_loss_list.append(gen_loss)\n",
    "            disc_loss_list.append(disc_loss)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}, Gen Loss: {np.mean(gen_loss_list):.4f}, Disc Loss: {np.mean(disc_loss_list):.4f}, Time: {time.time()-start:.2f} sec')\n",
    "\n",
    "def train_diffusion(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        loss_list = []\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            loss = train_step_diffusion(image_batch)\n",
    "            loss_list.append(loss)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}, Loss: {np.mean(loss_list):.4f}, Time: {time.time()-start:.2f} sec')\n",
    "\n",
    "# Generate images\n",
    "def generate_and_save_images(model, epoch, test_input, model_name):\n",
    "    predictions = model(test_input, training=False)\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 0.5 + 0.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig(f'generated_images/{model_name}_epoch_{epoch:04d}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Train models\n",
    "EPOCHS = 15\n",
    "print(\"Training DCGAN...\")\n",
    "train_gan(train_dataset, EPOCHS)\n",
    "print(\"\\nTraining Diffusion Model...\")\n",
    "train_diffusion(train_dataset, EPOCHS)\n",
    "\n",
    "# Generate and save images\n",
    "noise = tf.random.normal([16, 100])\n",
    "generate_and_save_images(generator, EPOCHS, noise, \"dcgan\")\n",
    "\n",
    "noisy_samples = train_images[:16] + 0.1 * tf.random.normal(shape=(16, 28, 28, 1))\n",
    "generate_and_save_images(diffusion_model, EPOCHS, noisy_samples, \"diffusion\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
